"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6806],{4907:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>h});var a=n(9953);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),m=u(n),h=i,c=m["".concat(s,".").concat(h)]||m[h]||d[h]||r;return n?a.createElement(c,l(l({ref:t},p),{},{components:n})):a.createElement(c,l({ref:t},p))}));function h(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,l=new Array(r);l[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,l[1]=o;for(var u=2;u<r;u++)l[u]=n[u];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},3510:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>o,toc:()=>u});var a=n(9440),i=(n(9953),n(4907));const r={title:"Raptor Spec",sidebar_label:"Architectural Design",sidebar_position:99,id:"spec"},l="Feature Definitions",o={unversionedId:"reference/spec",id:"reference/spec",title:"Raptor Spec",description:"Feature Definitions are an abstraction that contains metadata about the feature that should lead to create a Feature Value.",source:"@site/docs/reference/spec.md",sourceDirName:"reference",slug:"/reference/spec",permalink:"/docs/reference/spec",draft:!1,editUrl:"https://github.com/raptor-ml/docs/tree/master/docs/reference/spec.md",tags:[],version:"current",sidebarPosition:99,frontMatter:{title:"Raptor Spec",sidebar_label:"Architectural Design",sidebar_position:99,id:"spec"},sidebar:"reference",previous:{title:"time",permalink:"/docs/reference/pyexp/raptor-built-ins/time"}},s={},u=[{value:"Feature Value",id:"feature-value",level:2},{value:"Kubernetes Controller",id:"kubernetes-controller",level:2},{value:"Core&#39;s engine",id:"cores-engine",level:2},{value:"Core&#39;s operator",id:"cores-operator",level:2},{value:"Low-level API",id:"low-level-api",level:2},{value:"Online-aggregations",id:"online-aggregations",level:2},{value:"Snapshotting",id:"snapshotting",level:2},{value:"Regular features snapshotting",id:"regular-features-snapshotting",level:3},{value:"Windowed features snapshotting",id:"windowed-features-snapshotting",level:3},{value:"Synchronization process",id:"synchronization-process",level:2},{value:"Collect Notifications",id:"collect-notifications",level:3},{value:"Write jobs:",id:"write-jobs",level:3}],p={toc:u};function d(e){let{components:t,...r}=e;return(0,i.kt)("wrapper",(0,a.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"feature-definitions"},"Feature Definitions"),(0,i.kt)("p",null,"Feature Definitions are an abstraction that contains metadata about the feature that should lead to create a Feature Value."),(0,i.kt)("p",null,"Feature definitions contains:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"FQN (Fully Qualified Name): a unique name which is the composition of ",(0,i.kt)("inlineCode",{parentName:"li"},"{name}.{namespace}[aggr_fn?]")),(0,i.kt)("li",{parentName:"ul"},"Primitive Type:"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Int")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"String")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Float")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Timestamp")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"[]Int")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"[]String")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"[]Float")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"[]Timestamp")),(0,i.kt)("li",{parentName:"ul"},"Freshness duration - The duration which within the feature value is considered as fresh, and shouldn't be recalculated"),(0,i.kt)("li",{parentName:"ul"},"Staleness duration - The duration which after it the feature is considered as stale and ",(0,i.kt)("em",{parentName:"li"},"is invalid")," to be used.\nThe state should evict/expire that value after that, and only story it for historical purposes."),(0,i.kt)("li",{parentName:"ul"},"Timeout duration - The maximum time the server should respond with a feature value. In this time it tries to get\nthe most fresh value it can provide (considering the above constrains)")),(0,i.kt)("h2",{id:"feature-value"},"Feature Value"),(0,i.kt)("p",null,"The Feature Value is the computed value of a feature's ingestion."),(0,i.kt)("p",null,"Properties:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"fqn")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"entity_id")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"value")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"timestamp"))),(0,i.kt)("h1",{id:"core"},"Core"),(0,i.kt)("p",null,'The Core is the main component of Raptor. It acts as a "compiler" for the Raptor Feature Definitions, and responsible\nfor the "production" implementation for these definitions.'),(0,i.kt)("p",null,"The Core is responsible to:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Read the Feature Definitions"),(0,i.kt)("li",{parentName:"ol"},'Create an appropriate "builder" for each Feature Definition using the internal ',"[read/write pipelines][#Pipleines]",",\nand ","[runners][#Data-ingestion]"),(0,i.kt)("li",{parentName:"ol"},"Maintain the orchestration and monitoring of the system")),(0,i.kt)("p",null,"It has a few key components:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"[Engine][#Cores-engine]"," - responsible for the feature pipeline implementation"),(0,i.kt)("li",{parentName:"ol"},"[Operator][#Cores-operator]"," - responsible for the orchestration of the system(including spawning different services)"),(0,i.kt)("li",{parentName:"ol"},"State- responsible for the state of the system, including the state of the features and the\nstate of the system itself"),(0,i.kt)("li",{parentName:"ol"},"Accesssor - responsible for the access to the state of the system via the API"),(0,i.kt)("li",{parentName:"ol"},"Plugin system - responsible for the loading of the plugins")),(0,i.kt)("h2",{id:"kubernetes-controller"},"Kubernetes Controller"),(0,i.kt)("p",null,"The Kubernetes controller enables the user to use Raptor using the Kubernetes world. It is implemented as a part of the\nCore."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The controller supports validation on time of manifest create"),(0,i.kt)("li",{parentName:"ul"},'It "read and implement" the CRDs',(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Feature - defines a feature metadata & business logic"),(0,i.kt)("li",{parentName:"ul"},"DataConnector - defines a connector configuration (i.e. how to connect to Kafka, what's the creds, what's the\ntopic,\nschema, allocated resources, etc.)"),(0,i.kt)("li",{parentName:"ul"},"FeatureSet - defines a set of features."))),(0,i.kt)("li",{parentName:"ul"},"Update operations for Features are blocked by default and will be enabled ",(0,i.kt)("em",{parentName:"li"},"only by enabling a special flag"),".")),(0,i.kt)("h2",{id:"cores-engine"},"Core's engine"),(0,i.kt)("p",null,"The Core's engine is responsible for accessing and processing the feature values, as well as storing them in the State,\nand executing pipelines."),(0,i.kt)("h2",{id:"cores-operator"},"Core's operator"),(0,i.kt)("p",null,"The Core's operator is responsible for the orchestration of the system. It is responsible for the following:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Spawning the different services such as Runners"),(0,i.kt)("li",{parentName:"ol"},"Modifying the CR's status"),(0,i.kt)("li",{parentName:"ol"},"Implementing CR's webhooks")),(0,i.kt)("h2",{id:"low-level-api"},"Low-level API"),(0,i.kt)("p",null,"The low-level API (aka Engine API) support low-level operations over feature values:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Mutate features:"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"SET(fqn, entity_id, value, timestamp?)")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"GET(fqn, entity_id, timestamp?)")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"UPDATE(fqn, entity_id, value, timestamp?)")," - set value or append to a list"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"INCR(fqn, entity_id, by, timestamp?)")," - increment a value in a scalar (not for online aggr.)"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"APPEND(fqn, entity_id, value, timestamp?)")," - append a value to a list"),(0,i.kt)("li",{parentName:"ul"},"LIST of features"),(0,i.kt)("li",{parentName:"ul"},"GET feature-set (implemented as a feature builder)"),(0,i.kt)("li",{parentName:"ul"},"SET in bulk")),(0,i.kt)("h2",{id:"online-aggregations"},"Online-aggregations"),(0,i.kt)("p",null,"The engine support online aggregation (using the bucket algorithm)"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"SUM"),(0,i.kt)("li",{parentName:"ul"},"MAX"),(0,i.kt)("li",{parentName:"ul"},"MIN"),(0,i.kt)("li",{parentName:"ul"},"AVG"),(0,i.kt)("li",{parentName:"ul"},"COUNT")),(0,i.kt)("h1",{id:"pipelines"},"Pipelines"),(0,i.kt)("p",null,'Getting and Setting values to the State is done using the "pipeline". The pipeline is composed by a chain of middleware\nfunctions that wraps the access to/from the State by the priority(the lowest priority, the earlier it\'s executed) that\neach middleware is defined with:'),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-mermaid"},'graph LR\n  subgraph Get Pipeline\n    PreG["Pre Get #1"] -- 1...n --\x3e PreG99["Pre Get #99"] --\x3e Get[Get from the State] --\x3e PostG["Post Get #1"] -- 1...n --\x3e PostG99["Post Get #99"]\n  end\n  subgraph Set Pipeline\n    PreS["Pre Set #1"] -- 1...n --\x3e PreS99["Pre Set #99"] --\x3e Set[Set to the State] --\x3e PostS["Post Set #1"] -- 1...n --\x3e PostS99["Post Set #99"]\n  end\n')),(0,i.kt)("p",null,"The middlewares allow chaining a set of functions when getting or setting a value, in order to mutate the value (or to\nprevent the operation). This is useful for implementing a variety of features, including:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Validations - validations are PreSet middlewares"),(0,i.kt)("li",{parentName:"ul"},"DataConnectors that retrieve the data on the time-of-request (i.e. REST API)"),(0,i.kt)("li",{parentName:"ul"},"Transformations"),(0,i.kt)("li",{parentName:"ul"},'Encoders - i.e. attach "hashing" for the value at PostGet')),(0,i.kt)("h1",{id:"builders"},"Builders"),(0,i.kt)("p",null,"Builders are the composition of all the elements required to create a feature value:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Builder Kind - specifies the type of the builder composer. This is the unit that composing the pipeline and the\nimplementation details of the builder (and sometimes responsible for the connector implementation)."),(0,i.kt)("li",{parentName:"ol"},"Aggregations definition (if any)"),(0,i.kt)("li",{parentName:"ol"},"PyExp code")),(0,i.kt)("p",null,"To build features, the builder required to pull configurations from two places:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"DataConnector CRD - defining the connection configuration"),(0,i.kt)("li",{parentName:"ul"},"Feature CRD - defining the business logic of a feature creation\n",(0,i.kt)("img",{alt:"Shape1",src:n(1637).Z,width:"1152",height:"864"}))),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Builders are an amorphic concept that unite together a set of instructions how to build the feature value.\nThere is no one unit that implements it.")),(0,i.kt)("h1",{id:"data-ingestion"},"Data ingestion"),(0,i.kt)("p",null,"Data ingestion can be implemented externally or internally"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},'Externally - as a standalone service (aka "Runner" deployment)\nThis can be implemented by writing a custom microservice (i.e. for webhook or streaming connectors)')),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},'Internally - in-process of the "Core", utilizing the GET/SET pipeline.\nThis can be implemented by writing a "plugin" to that adds a middleware for this feature'))),(0,i.kt)("p",null,'Writing data as "feature value" is done using the "low-level API" (whether it\'s internally via the library or externally\nby the runtime sidecar)'),(0,i.kt)("h1",{id:"historian"},"Historian"),(0,i.kt)("p",null,"The historian is responsible to keep records of the (current) State (of the world), to a storage.\nIt does that by scheduling a periodic snapshotting of the State to the storage."),(0,i.kt)("h2",{id:"snapshotting"},"Snapshotting"),(0,i.kt)("p",null,"Snapshotting is the process that is responsible for copying data from the real-time/online state to the historical\nstorage."),(0,i.kt)("p",null,"This process is composed of 3 different sub-processes:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Regular features snapshotting")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Scheduled Windowed-features snapshotting")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Storing process")," - Synchronizes write calls")),(0,i.kt)("h3",{id:"regular-features-snapshotting"},"Regular features snapshotting"),(0,i.kt)("p",null,"We are keeping every ",(0,i.kt)("strong",{parentName:"p"},"change")," to the feature. To do that we just need to hook in just after the write in the pipeline."),(0,i.kt)("p",null,"Every feature's writing request in the pipeline triggers writing to a distributed queue:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Pipeline: write"),(0,i.kt)("li",{parentName:"ol"},"\u2192Pipeline: Go routing to ",(0,i.kt)("inlineCode",{parentName:"li"},"Historian.AddWriteNotification(fqn, entityId,value)")),(0,i.kt)("li",{parentName:"ol"},"\u2192Historian library: write a ",(0,i.kt)("em",{parentName:"li"},"notification message")," to a Redis stream")),(0,i.kt)("h3",{id:"windowed-features-snapshotting"},"Windowed features snapshotting"),(0,i.kt)("p",null,"Due to the different behavior and volatility of windowed features, a different implementation is required:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("em",{parentName:"li"},"Windowed features")," are prune to MANY writes (due to the fact they are used to storing aggregations)"),(0,i.kt)("li",{parentName:"ul"},"Copying every change is expensive, inefficient and duplicating the raw data under the hood."),(0,i.kt)("li",{parentName:"ul"},"We are triggering snapshotting of windowed features by:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"A periodic snapshotting (every 5 minutes)"),(0,i.kt)("li",{parentName:"ul"},'Trigger an "update notification" when a windowed feature is written to')))),(0,i.kt)("p",null,"To support the above, we are required to keep buckets in the state a little longer to make sure we're collecting them."),(0,i.kt)("h2",{id:"synchronization-process"},"Synchronization process"),(0,i.kt)("p",null,"The Synchronization process is running only on a leader instance.\nIt utilizes an internal job queue combines duplicated ",(0,i.kt)("em",{parentName:"p"},"writes")," and ",(0,i.kt)("em",{parentName:"p"},"collection")," notifications, and handles them."),(0,i.kt)("h3",{id:"collect-notifications"},"Collect Notifications"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"collect the values"),(0,i.kt)("li",{parentName:"ul"},"Add a ",(0,i.kt)("em",{parentName:"li"},"writing job")," of the results")),(0,i.kt)("h3",{id:"write-jobs"},"Write jobs:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The Writing process is running only on a leader instance."),(0,i.kt)("li",{parentName:"ul"},"Writing the historical records to Historical Provider (i.e. Parquet S3, Snowflake, BigQuery, etc.)")),(0,i.kt)("h1",{id:"glossary"},"Glossary"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"CRD - Custom Resource Definition"),(0,i.kt)("li",{parentName:"ul"},"Feature - A data input for the model which describes a trait of our data"),(0,i.kt)("li",{parentName:"ul"},"Feature Definition/Manifest - A feature's business logic declarative code. This is used by data scientists(via the\nLabSDK) to describe how the Core should generate feature values from ",(0,i.kt)("em",{parentName:"li"},"raw data")," and how the platform should store it."),(0,i.kt)("li",{parentName:"ul"},"FeatureSet - A set of features that are used to serve a specific model."),(0,i.kt)("li",{parentName:"ul"},"DataConnector - A ",(0,i.kt)("em",{parentName:"li"},"conceptual")," unit that retrieves the data from the production system. Sometimes it's an actual unit(\ni.e. Kafka Runner), and sometimes it's just configuring a program."),(0,i.kt)("li",{parentName:"ul"},"DataConnector Manifest - The configuration of the DataConnector"),(0,i.kt)("li",{parentName:"ul"},"Core - The main platform's program. This is the unit that is responsible to glue it all together"),(0,i.kt)("li",{parentName:"ul"},"Read/Write pipeline - The pipeline of fetching/setting data from/to the storage. At its middle, we have the actual\noperation of the storage."),(0,i.kt)("li",{parentName:"ul"},"Middlewares - The steps that wrap the read/write of the store"),(0,i.kt)("li",{parentName:"ul"},"Runner - A unit that is running outside the Core and responsible"),(0,i.kt)("li",{parentName:"ul"},"Historical Provider - the historical storage implementation. We're taking snapshots of the current state to it."),(0,i.kt)("li",{parentName:"ul"},"State - The state is the unit the stores the feature values to be served to models. It describes the current state of\nthe world.")))}d.isMDXComponent=!0},1637:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/spec.builders-bd7aa9984b41f9f5ff180834deb1488b.png"}}]);